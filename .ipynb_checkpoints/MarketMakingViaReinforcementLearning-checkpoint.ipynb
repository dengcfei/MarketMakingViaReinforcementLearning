{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dengcfei/MarketMakingViaReinforcementLearning/blob/main/MarketMakingViaReinforcementLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sab6l-iY0xAV",
    "outputId": "22683ac4-bb3a-464e-a4d0-a7332e41e624"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#check env\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "#check env\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "print(sys.version, nltk.__version__, tf.__version__, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cW8tTjfx3lWE"
   },
   "outputs": [],
   "source": [
    "#utility\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def min_max_norm(data):\n",
    "    minVals = data.min()\n",
    "    maxVals = data.max()\n",
    "    ranges = maxVals - minVals\n",
    "    if ranges==0:\n",
    "        return data*0\n",
    "    normData = data - minVals\n",
    "    normData = normData/ranges\n",
    "    return normData\n",
    "\n",
    "def z_norm(data):\n",
    "    return (data-data.mean())/(data.std()+1e-7)\n",
    "\n",
    "def lob_norm(data_, midprice):\n",
    "    data = data_.copy()\n",
    "    for i in range(10):\n",
    "        data[f'ask{i+1}_price'] = data[f'ask{i+1}_price']/(midprice+1e-7) - 1\n",
    "        data[f'bid{i+1}_price'] = data[f'bid{i+1}_price']/(midprice+1e-7) - 1\n",
    "        # data[f'ask{i+1}_price'] = z_norm(data[f'ask{i+1}_price'])\n",
    "        # data[f'bid{i+1}_price'] = z_norm(data[f'bid{i+1}_price'])\n",
    "        data[f'ask{i+1}_volume'] = data[f'ask{i+1}_volume']/data[f'ask{i+1}_volume'].max()\n",
    "        data[f'bid{i+1}_volume'] = data[f'bid{i+1}_volume']/data[f'bid{i+1}_volume'].max()\n",
    "\n",
    "    return data\n",
    "\n",
    "def onehot_label(targets):\n",
    "    from tensorflow import keras\n",
    "    # targets: pd.DataFrame len(data)*n_horizons\n",
    "    all_label = []\n",
    "    for i in range(targets.shape[1]):\n",
    "        label = targets.iloc[:,i] - 1\n",
    "        label = keras.utils.to_categorical(label, 3)\n",
    "        # label = label.reshape(len(label), 1, 3)\n",
    "        all_label.append(label)\n",
    "    return np.hstack(all_label)\n",
    "\n",
    "def day2date(day):\n",
    "    day = list(day)\n",
    "    day.insert(4,'-')\n",
    "    day.insert(7,'-')\n",
    "    date = ''.join(day)\n",
    "    return date\n",
    "\n",
    "def pd_is_equal(state_1, state_2):\n",
    "    tmp_1 = state_1.iloc[:,1:]\n",
    "    tmp_2 = state_2.iloc[:,1:]\n",
    "    return tmp_1.equals(tmp_2)\n",
    "\n",
    "def load_data(code, datelist, horizon=10):\n",
    "    if type(datelist) is str:\n",
    "        datelist = [datelist]\n",
    "    data_list = []\n",
    "    for day in datelist:\n",
    "        ask = pd.read_csv(f\"data/{code}/{day}/ask.csv\")\n",
    "        bid = pd.read_csv(f\"data/{code}/{day}/bid.csv\").drop(['timestamp'], axis = 1)\n",
    "        price = pd.read_csv(f\"data/{code}/{day}/price.csv\").drop(['timestamp', 'ask1_price', 'bid1_price'], axis = 1)\n",
    "        data = pd.concat([ask, bid, price], axis=1)\n",
    "        data['date'] = data['timestamp'].str.split(expand=True)[0]\n",
    "        data['time'] = data['timestamp'].str.split(expand=True)[1]\n",
    "        data.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "        data['y']=getLabel(data.midprice, horizon)\n",
    "\n",
    "        data_list.append(data)\n",
    "    return pd.concat(data_list)\n",
    "\n",
    "def getLabel(mid_price, horizon, threshold=1e-5):\n",
    "    price_past = mid_price.rolling(window=horizon).mean()\n",
    "\n",
    "    price_future = mid_price.copy()\n",
    "    price_future[:-horizon] = price_past[horizon:]\n",
    "    price_future[-horizon:] = np.nan\n",
    "\n",
    "    pct_change = (price_future - price_past)/price_past\n",
    "    pct_change[pct_change>=threshold] = 1\n",
    "    pct_change[(pct_change<threshold) & (-threshold<pct_change)] = 2\n",
    "    pct_change[pct_change<=-threshold] = 3\n",
    "    return pct_change\n",
    "\n",
    "def process_data(data):\n",
    "    data = data[(data.time > '10:00:00')&(data.time < '14:30:00')]\n",
    "    data = data.dropna()\n",
    "    data.y = data.y.astype(int)\n",
    "\n",
    "    for i in range(10):\n",
    "        data[f'ask{i+1}_price'] = data[f'ask{i+1}_price']/data['midprice'] - 1\n",
    "        data[f'bid{i+1}_price'] = data[f'bid{i+1}_price']/data['midprice'] - 1\n",
    "        # data[f'ask{i+1}_price'] = z_norm(data[f'ask{i+1}_price'])\n",
    "        # data[f'bid{i+1}_price'] = z_norm(data[f'bid{i+1}_price'])\n",
    "        data[f'ask{i+1}_volume'] = data[f'ask{i+1}_volume']/data[f'ask{i+1}_volume'].max()\n",
    "        data[f'bid{i+1}_volume'] = data[f'bid{i+1}_volume']/data[f'bid{i+1}_volume'].max()\n",
    "\n",
    "    return data.set_index(['date', 'time'])\n",
    "\n",
    "def reorder(data):\n",
    "    '''\n",
    "    reorder the data to this order:\n",
    "    ask1_v, ask1_p, bid1_v, bid1_p ... ask10_v, ask10_p, bid10_v, bid10_p\n",
    "    '''\n",
    "    data=np.array(data)\n",
    "    data=data.reshape(data.shape[0], 4, 10)\n",
    "    data= np.transpose(data, (0,2,1))\n",
    "    data = data.reshape(data.shape[0], -1)\n",
    "    return data\n",
    "\n",
    "def data_classification(X, Y, T):\n",
    "    [N, D] = X.shape\n",
    "    df = np.array(X)\n",
    "\n",
    "    dY = np.array(Y)\n",
    "\n",
    "    dataY = dY[T - 1:N]\n",
    "\n",
    "    dataX = np.zeros((N - T + 1, T, D))\n",
    "    for i in range(T, N + 1):\n",
    "        dataX[i - T] = df[i - T:i, :]\n",
    "\n",
    "    return dataX.reshape(dataX.shape + (1,)), dataY\n",
    "\n",
    "def price_legal_check(ask_price, bid_price):\n",
    "    # legal check\n",
    "    ask_price = math.ceil(100*ask_price)/100\n",
    "    bid_price = math.floor(100*bid_price)/100\n",
    "    return ask_price, bid_price\n",
    "\n",
    "def getRealizedVolatility(data, resample='min'):\n",
    "    if resample:\n",
    "        data = data.resample(resample).last()\n",
    "\n",
    "    midprice_lag = data.shift(1)\n",
    "    midprice_log = data.apply(np.log)\n",
    "    midprice_lag_log = midprice_lag.apply(np.log)\n",
    "    r = midprice_log - midprice_lag_log\n",
    "    r2 = r*r\n",
    "    rv = r2.sum()\n",
    "\n",
    "    return rv\n",
    "\n",
    "def getRelativeStrengthIndex(data):\n",
    "    length = len(data)\n",
    "    data = data.resample('s').last()\n",
    "    data = data.pct_change(1)\n",
    "    gain = data[data>0].sum()/length\n",
    "    loss = -data[data<0].sum()/length\n",
    "    if gain or loss:\n",
    "        rsi = gain/(gain+loss)\n",
    "    else:\n",
    "        rsi = .5\n",
    "    return rsi\n",
    "\n",
    "def getOrderStrengthIndex(data):\n",
    "    '''\n",
    "    data: msg\n",
    "    columns:[market_buy_volume  market_buy_n  market_sell_volume  market_sell_n  limit_buy_volume  limit_buy_n  limit_sell_volume  limit_sell_n  withdraw_buy_volume  withdraw_buy_n  withdraw_sell_volume  withdraw_sell_n]\n",
    "    '''\n",
    "    market_volume_intensity = (data.market_buy_volume.sum() - data.market_sell_volume.sum())/(data.market_buy_volume.sum() + data.market_sell_volume.sum() + 1e-7)\n",
    "    market_number_intensity = (data.market_buy_n.sum() - data.market_sell_n.sum())/(data.market_buy_n.sum() + data.market_sell_n.sum() + 1e-7)\n",
    "    limit_volume_intensity = (data.limit_buy_volume.sum() - data.limit_sell_volume.sum())/(data.limit_buy_volume.sum() + data.limit_sell_volume.sum() + 1e-7)\n",
    "    limit_number_intensity = (data.limit_buy_n.sum() - data.limit_sell_n.sum())/(data.limit_buy_n.sum() + data.limit_sell_n.sum() + 1e-7)\n",
    "    withdraw_volume_intensity = (data.withdraw_buy_volume.sum() - data.withdraw_sell_volume.sum())/(data.withdraw_buy_volume.sum() + data.withdraw_sell_volume.sum() + 1e-7)\n",
    "    withdraw_number_intensity = (data.withdraw_buy_n.sum() - data.withdraw_sell_n.sum())/(data.withdraw_buy_n.sum() + data.withdraw_sell_n.sum() + 1e-7)\n",
    "\n",
    "    return market_volume_intensity, market_number_intensity, limit_volume_intensity, limit_number_intensity, withdraw_volume_intensity, withdraw_number_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-5ac14X92z82"
   },
   "outputs": [],
   "source": [
    "#base_env\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from tensorforce import Environment\n",
    "\n",
    "\n",
    "\n",
    "TRADE_UNIT = 100\n",
    "\n",
    "class BaseEnv():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            initial_value=0,\n",
    "            max_episode_timesteps=1000,\n",
    "            data_dir='./data',\n",
    "            log=1,\n",
    "            experiment_name='',\n",
    "            **kwargs\n",
    "            ):\n",
    "        super().__init__()\n",
    "        self.name = ''\n",
    "        self.initial_value = initial_value\n",
    "        self.__max_episode_timesteps__=max_episode_timesteps\n",
    "        self.data_dir = data_dir\n",
    "        self.log = log\n",
    "        self.exp_name = experiment_name\n",
    "\n",
    "    '''\n",
    "        You need to overload these functions\n",
    "    '''\n",
    "\n",
    "    def states(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def actions(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def action2order(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_state_at_t(self, t):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_reward(self, trade_price, trade_volume):\n",
    "        # Define reward function here\n",
    "        reward = self.value - self.value_\n",
    "        self.value_ = self.value\n",
    "        return reward\n",
    "\n",
    "    '''\n",
    "        Load data\n",
    "    '''\n",
    "\n",
    "    def load_orderbook(self, code, day):\n",
    "        ask = pd.read_csv(self.data_dir + f'/{code}/{day}/ask.csv')\n",
    "        bid = pd.read_csv(self.data_dir + f'/{code}/{day}/bid.csv').drop(['timestamp'], axis = 1)\n",
    "\n",
    "        self.orderbook = pd.concat([ask, bid], axis=1)\n",
    "        self.orderbook.timestamp = pd.to_datetime(self.orderbook.timestamp)\n",
    "        self.orderbook = self.orderbook[(f'{self.day} 09:30:00'<self.orderbook.timestamp)&(self.orderbook.timestamp<f'{self.day} 14:57:00')]\n",
    "        self.orderbook = self.orderbook.set_index('timestamp')\n",
    "        self.orderbook_length = len(self.orderbook)\n",
    "        print('load lob done!', code, day)\n",
    "\n",
    "    def load_orderqueue(self, code, day):\n",
    "        pass\n",
    "\n",
    "    def load_price(self, code, day):\n",
    "        self.price = pd.read_csv(self.data_dir + f'/{code}/{day}/price.csv')\n",
    "        self.price.timestamp = pd.to_datetime(self.price.timestamp)\n",
    "        self.price = self.price.set_index('timestamp')\n",
    "        self.price = self.price.loc[self.orderbook.index]\n",
    "\n",
    "    def load_msg(self, code, day):\n",
    "        self.msg = pd.read_csv(self.data_dir + f'/{code}/{day}/msg.csv')\n",
    "        self.msg.timestamp = pd.to_datetime(self.msg.timestamp)\n",
    "        self.msg = self.msg.set_index('timestamp')\n",
    "        self.msg = self.msg.loc[self.orderbook.index]\n",
    "\n",
    "    def load_order(self, code, day):\n",
    "        order_columns = pd.read_csv('raw/GTA_SZL2_ORDER.csv')\n",
    "        self.order = pd.read_csv(f'raw/SZL2_ORDER_{code}_{day[:6]}.csv', names=list(order_columns), low_memory=False)\n",
    "        self.order.TradingTime = pd.to_datetime(self.order.TradingTime)\n",
    "        self.order = self.order[self.order.TradingDate==int(day)]\n",
    "        self.order = self.order[(f'{self.day} 09:30:00'<self.order.TradingTime)&(self.order.TradingTime<f'{self.day} 14:57:00')]\n",
    "\n",
    "    def load_trade(self, code, day):\n",
    "        trade_columns = pd.read_csv('raw/GTA_SZL2_TRADE.csv')\n",
    "        self.trade = pd.read_csv(f'raw/SZL2_TRADE_{code}_{day[:6]}.csv', names=list(trade_columns))\n",
    "        self.trade.TradingTime = pd.to_datetime(self.trade.TradingTime)\n",
    "        self.trade = self.trade[self.trade.TradingDate==int(day)]\n",
    "        self.trade = self.trade[self.trade.TradeType==\"F\"]\n",
    "        self.trade = self.trade[(f'{self.day} 09:30:00'<self.trade.TradingTime)&(self.trade.TradingTime<f'{self.day} 14:57:00')]\n",
    "\n",
    "        self.is_trade = pd.DataFrame(index=self.orderbook.index,columns=['is_trade'])\n",
    "        self.is_trade['is_trade'] = 0\n",
    "        self.is_trade.loc[set(self.trade.TradingTime)] = 1\n",
    "\n",
    "    '''\n",
    "        Common function\n",
    "    '''\n",
    "\n",
    "    def reset_seq(self, timesteps_per_episode=None, episode_idx=None):\n",
    "        self.episode_idx = episode_idx\n",
    "        if timesteps_per_episode == None:\n",
    "            self.episode_start = 0\n",
    "            self.episode_end = len(self.orderbook)\n",
    "            self.episode_state = self.orderbook\n",
    "        else:\n",
    "            self.episode_start = timesteps_per_episode * episode_idx\n",
    "            self.episode_end = min(self.episode_start + timesteps_per_episode, len(self.orderbook))\n",
    "            self.episode_state = self.orderbook.iloc[self.episode_start:self.episode_end]\n",
    "\n",
    "        self.episode_length = len(self.episode_state)\n",
    "\n",
    "        episode_is_trade = self.is_trade.iloc[self.episode_start:self.episode_end]\n",
    "        has_trade_index = np.where(episode_is_trade==1)[0]\n",
    "        has_trade_index = has_trade_index[has_trade_index>self.T]\n",
    "        self.index_iterator = iter(has_trade_index)\n",
    "\n",
    "        self.cash = self.value_ = self.value = self.initial_value\n",
    "        self.holding_pnl_total = self.trading_pnl_total = 0\n",
    "        self.inventory = 0\n",
    "        self.volume = 0\n",
    "        self.episode_reward = 0\n",
    "        self.mid_price_ = None\n",
    "        self.action_his = []\n",
    "        self.reward_dampened_pnl = 0\n",
    "        self.reward_trading_pnl = 0\n",
    "        self.reward_inventory_punishment = 0\n",
    "        self.reward_spread_punishment = 0\n",
    "\n",
    "        # log for trade\n",
    "        self.logger = self.price.iloc[self.episode_start:self.episode_end].copy()\n",
    "        columns=['ask_price', 'bid_price', 'trade_price', 'trade_volume', 'value', 'volume', 'cash', 'inventory']\n",
    "        for column in columns:\n",
    "            self.logger[column] = np.nan\n",
    "\n",
    "        self.i = next(self.index_iterator)\n",
    "        self.i_ = next(self.index_iterator)\n",
    "        state = self.get_state_at_t(self.i-self.latency)\n",
    "\n",
    "        if self.log >= 1:\n",
    "            print(f'Reset env {self.name} {self.code}, {self.day}, from {self.episode_state.index[0]} to {self.episode_state.index[-1]}')\n",
    "            self.pbar = tqdm(total=self.episode_length)\n",
    "            self.pbar.update(self.i)\n",
    "\n",
    "        return state\n",
    "\n",
    "    def reset_random(self, timesteps_per_episode=2000):\n",
    "        self.episode_start = np.random.randint(0, len(self.orderbook) - timesteps_per_episode)\n",
    "        self.episode_end = min(self.episode_start + timesteps_per_episode, len(self.orderbook))\n",
    "        self.episode_state = self.orderbook.iloc[self.episode_start:self.episode_end]\n",
    "\n",
    "        self.episode_length = len(self.episode_state)\n",
    "\n",
    "        episode_is_trade = self.is_trade.iloc[self.episode_start:self.episode_end]\n",
    "        has_trade_index = np.where(episode_is_trade==1)[0]\n",
    "        has_trade_index = has_trade_index[has_trade_index>self.T]\n",
    "        self.index_iterator = iter(has_trade_index)\n",
    "\n",
    "        self.cash = self.value_ = self.value = self.initial_value\n",
    "        self.holding_pnl_total = self.trading_pnl_total = 0\n",
    "        self.inventory = 0\n",
    "        self.volume = 0\n",
    "        self.episode_reward = 0\n",
    "        self.mid_price_ = None\n",
    "        self.action_his = []\n",
    "        self.reward_dampened_pnl = 0\n",
    "        self.reward_trading_pnl = 0\n",
    "        self.reward_inventory_punishment = 0\n",
    "        self.reward_spread_punishment = 0\n",
    "\n",
    "        # log for trade\n",
    "        self.logger = self.price.iloc[self.episode_start:self.episode_end].copy()\n",
    "        columns=['ask_price', 'bid_price', 'trade_price', 'trade_volume', 'value', 'volume', 'cash', 'inventory']\n",
    "        for column in columns:\n",
    "            self.logger[column] = np.nan\n",
    "\n",
    "        self.i = next(self.index_iterator)\n",
    "        self.i_ = next(self.index_iterator)\n",
    "        state = self.get_state_at_t(self.i-self.latency)\n",
    "\n",
    "        if self.log:\n",
    "            print(f'Reset env {self.name} {self.code}, {self.day}, from {self.episode_state.index[0]} to {self.episode_state.index[-1]}')\n",
    "            self.pbar = tqdm(total=self.episode_length)\n",
    "            self.pbar.update(self.i)\n",
    "\n",
    "        return state\n",
    "\n",
    "    def execute(self, actions):\n",
    "        self.action_his.append(actions)\n",
    "        # t\n",
    "        self.mid_price, self.ask1_price, self.bid1_price, self.lob_spread = self.get_price_info(self.i)\n",
    "        if self.mid_price_ == None:\n",
    "            self.mid_price_ = self.mid_price\n",
    "\n",
    "        orders = self.action2order(actions)\n",
    "        # inventory limit\n",
    "        if self.inventory < -10*TRADE_UNIT:\n",
    "            orders['ask_price']=0\n",
    "        elif self.inventory > 10*TRADE_UNIT:\n",
    "            orders['bid_price']=0\n",
    "\n",
    "        trade_price, trade_volume = self.match(orders)\n",
    "\n",
    "        self.update_agent(trade_price, trade_volume)\n",
    "\n",
    "        # log for trade result\n",
    "        self.logger.iloc[self.i, -8:] = [orders['ask_price'], orders['bid_price'], trade_price, trade_volume, self.value, self.volume, self.cash, self.inventory]\n",
    "\n",
    "        # if trade_volume:\n",
    "        #     print(self.i, 'ask1:', self.ask1_price, 'bid1:', self.bid1_price, 'buy' if trade_volume>0 else 'sell', 'at', trade_price)\n",
    "        if self.log >= 1:\n",
    "            self.pbar.update(self.i_ - self.i)\n",
    "\n",
    "        self.i = self.i_\n",
    "        # Termination conditions\n",
    "        terminal = False\n",
    "        try:\n",
    "            self.i_ = next(self.index_iterator)\n",
    "        except:\n",
    "            terminal = True\n",
    "\n",
    "        reward = self.get_reward(trade_price, trade_volume)\n",
    "        self.mid_price_ = self.mid_price\n",
    "\n",
    "        # close position\n",
    "        if terminal:\n",
    "            trade_price, trade_volume = self.close_position()\n",
    "            reward += self.get_reward(trade_price, trade_volume)\n",
    "\n",
    "        self.episode_reward += reward\n",
    "\n",
    "        # log for result\n",
    "        if terminal:\n",
    "            self.post_experiment()\n",
    "\n",
    "        state = self.get_state_at_t(self.i-self.latency)\n",
    "\n",
    "        return state, terminal, reward\n",
    "\n",
    "    def match(self, actions):\n",
    "        trade_volume = 0\n",
    "        trade_price = 0\n",
    "        ask_price, ask_volume, bid_price, bid_volume = actions.values()\n",
    "\n",
    "        # trade\n",
    "        now_t = self.trade[self.trade.TradingTime==self.episode_state.index[self.i]]\n",
    "        now_trading_price_max = now_t.TradePrice.max()\n",
    "        now_trading_price_max_v = now_t[now_t.TradePrice==now_trading_price_max].TradeVolume.sum()\n",
    "        now_trading_price_min = now_t.TradePrice.min()\n",
    "        now_trading_price_min_v = now_t[now_t.TradePrice==now_trading_price_min].TradeVolume.sum()\n",
    "\n",
    "        # t - 1\n",
    "        t_1_mid_price, t_1_a1_price, t_1_b1_price, t_1_spread = self.get_price_info(self.i-1)\n",
    "\n",
    "        # sell order\n",
    "        if ask_price and ask_volume:\n",
    "            if ask_price <= t_1_b1_price:\n",
    "                # market order\n",
    "                trade_price, trade_volume = t_1_b1_price, ask_volume\n",
    "                # print(\"market order sell at\", trade_price)\n",
    "            else:\n",
    "                # limit order\n",
    "                if now_trading_price_max > ask_price:\n",
    "                    # all deal\n",
    "                    trade_price, trade_volume = ask_price, ask_volume\n",
    "                    # print(\"limit order sell at\", trade_price)\n",
    "\n",
    "                # we assume that our quotes rest at the back of the queue\n",
    "                elif now_trading_price_max == ask_price:\n",
    "                    # deal probability: traded volume/all volume in this level\n",
    "                    lob_depth = self.episode_state.iloc[self.i].ask1_volume\n",
    "                    transac_prob = now_trading_price_max_v/(now_trading_price_max_v+lob_depth)\n",
    "                    is_transac = np.random.choice([1, 0], p=[transac_prob, 1-transac_prob])\n",
    "                    if is_transac:\n",
    "                        trade_price, trade_volume = ask_price, ask_volume\n",
    "\n",
    "        # buy order\n",
    "        if bid_price and bid_volume:\n",
    "            if bid_price >= t_1_a1_price:\n",
    "                # market order\n",
    "                trade_price, trade_volume = t_1_a1_price, bid_volume\n",
    "                # print(\"market order buy at\", trade_price)\n",
    "            else:\n",
    "                if now_trading_price_min < bid_price:\n",
    "                    trade_price, trade_volume = bid_price, bid_volume\n",
    "                    # print(\"limit order buy at\", trade_price)\n",
    "\n",
    "                # we assume that our quotes rest at the back of the queue\n",
    "                elif now_trading_price_min == bid_price:\n",
    "                    lob_depth = self.episode_state.iloc[self.i].bid1_volume\n",
    "                    transac_prob = now_trading_price_min_v/(now_trading_price_min_v+lob_depth)\n",
    "                    is_transac = np.random.choice([1, 0], p=[transac_prob, 1-transac_prob])\n",
    "                    if is_transac:\n",
    "                        trade_price, trade_volume = bid_price, bid_volume\n",
    "\n",
    "        return trade_price, trade_volume\n",
    "\n",
    "    def close_position(self):\n",
    "        # t - 1\n",
    "        t_1_mid_price, t_1_a1_price, t_1_b1_price, t_1_spread = self.get_price_info(self.i-1)\n",
    "\n",
    "        # Market order\n",
    "        if self.inventory < 0:\n",
    "            # Buy\n",
    "            trade_price, trade_volume = t_1_a1_price, -self.inventory\n",
    "            self.volume += trade_volume\n",
    "        elif self.inventory > 0:\n",
    "            # Sell\n",
    "            trade_price, trade_volume = t_1_b1_price, -self.inventory\n",
    "        else:\n",
    "            trade_price, trade_volume = 0, 0\n",
    "\n",
    "        self.update_agent(trade_price, trade_volume)\n",
    "\n",
    "        # log for trade result\n",
    "        self.logger.iloc[self.i, -6:] = [trade_price, trade_volume, self.value, self.volume, self.cash, self.inventory]\n",
    "\n",
    "        return trade_price, trade_volume\n",
    "\n",
    "    def update_agent(self, trade_price, trade_volume):\n",
    "        self.inventory_ = self.inventory\n",
    "        self.inventory += trade_volume\n",
    "        self.cash -= trade_volume*trade_price\n",
    "        self.value = self.get_value(self.mid_price)\n",
    "\n",
    "        volume = max(0, trade_volume*trade_price) # only count for buy\n",
    "        self.volume += volume\n",
    "\n",
    "    def get_price_info(self, i):\n",
    "        price = self.price[self.price.index==self.episode_state.index[i]]\n",
    "\n",
    "        bid1_price = price.bid1_price.item()\n",
    "        ask1_price = price.ask1_price.item()\n",
    "        bid1_price, ask1_price = round(bid1_price,2), round(ask1_price,2)\n",
    "        mid_price = (bid1_price+ask1_price)/2\n",
    "        spread = ask1_price - bid1_price\n",
    "\n",
    "        return mid_price, ask1_price, bid1_price, spread\n",
    "\n",
    "    def get_value(self, price):\n",
    "        return self.cash + self.inventory*price\n",
    "\n",
    "    '''\n",
    "        For evaluation and save trading log\n",
    "    '''\n",
    "\n",
    "    def post_experiment(self, save=False):\n",
    "        logger_wo_exit_market = self.logger[(self.logger.ask_price != 0) & (self.logger.bid_price != 0)]\n",
    "        self.episode_avg_spread = (logger_wo_exit_market.ask_price - logger_wo_exit_market.bid_price).mean()\n",
    "        self.episode_avg_position = self.logger.inventory.mean()\n",
    "        self.episode_avg_abs_position = self.logger.inventory.abs().mean()\n",
    "        self.episode_profit_ratio = self.value/(self.volume+1e-7)\n",
    "        self.pnl = self.value - self.initial_value\n",
    "        self.nd_pnl = self.pnl/self.episode_avg_spread\n",
    "        self.pnl_map = self.pnl/(self.episode_avg_abs_position+1e-7)\n",
    "\n",
    "        if self.log >= 1:\n",
    "            print(\n",
    "                \"PnL:\", self.pnl,\n",
    "                \"Holding PnL\", self.holding_pnl_total,\n",
    "                \"Trading PnL\", self.trading_pnl_total,\n",
    "                \"ND-PnL:\", self.nd_pnl,\n",
    "                \"PnL-MAP:\", self.pnl_map,\n",
    "                \"Trading volume:\", self.volume,\n",
    "                \"Profit ratio:\", self.episode_profit_ratio,\n",
    "                \"Averaged position:\",self.episode_avg_position,\n",
    "                \"Averaged Abs position:\",self.episode_avg_abs_position,\n",
    "                \"Averaged spread:\", self.episode_avg_spread,\n",
    "                \"Episodic reward:\", self.episode_reward\n",
    "                )\n",
    "            self.pbar.close()\n",
    "\n",
    "        if self.log >= 2:\n",
    "            trade_log = self.logger[(self.logger.trade_volume > 0)|(self.logger.trade_volume < 0)]\n",
    "            for i in range(len(trade_log)):\n",
    "                item = trade_log.iloc[i]\n",
    "                if item.trade_volume > 0:\n",
    "                    print(item.name, 'BUY at', item.trade_price, 'inventory', item.inventory, 'value', item.value)\n",
    "                elif item.trade_volume < 0:\n",
    "                    print(item.name, 'SELL at', item.trade_price, 'inventory', item.inventory, 'value', item.value)\n",
    "\n",
    "        if save:\n",
    "            now_time = time.strftime('%Y_%m_%d_%H_%M_%S', time.localtime())\n",
    "            log_file = f\"./log/{self.exp_name}_{self.code}_{self.day}_{now_time}.csv\"\n",
    "            self.logger.to_csv(log_file)\n",
    "            print(\"Trading log saved to\", log_file)\n",
    "\n",
    "    def get_final_result(self):\n",
    "        return dict(\n",
    "            pnl=self.pnl,\n",
    "            nd_pnl=self.nd_pnl,\n",
    "            pnl_map=self.pnl_map,\n",
    "            profit_ratio=self.episode_profit_ratio,\n",
    "            avg_position=self.episode_avg_position,\n",
    "            avg_abs_position=self.episode_avg_abs_position,\n",
    "            avg_spread=self.episode_avg_spread,\n",
    "            volume=self.volume,\n",
    "            episode_reward=self.episode_reward\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ujGVWrkW3b11"
   },
   "outputs": [],
   "source": [
    "#env_feature\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "class EnvFeature(BaseEnv):\n",
    "    \"\"\"\n",
    "        Use this class to calculate your factor\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            **kwargs\n",
    "        ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def _get_market_state(self,t):\n",
    "        data_300s = self.price[(self.price.index<=self.episode_state.index[t])&(self.price.index>=self.episode_state.index[t]-timedelta(seconds=300))].midprice\n",
    "        data_600s = self.price[(self.price.index<=self.episode_state.index[t])&(self.price.index>=self.episode_state.index[t]-timedelta(seconds=600))].midprice\n",
    "        data_1800s = self.price[(self.price.index<=self.episode_state.index[t])&(self.price.index>=self.episode_state.index[t]-timedelta(seconds=1800))].midprice\n",
    "        rv_300s = getRealizedVolatility(data_300s,resample='s')*1e4\n",
    "        rv_600s = getRealizedVolatility(data_600s,resample='s')*1e4\n",
    "        rv_1800s = getRealizedVolatility(data_1800s,resample='s')*1e4\n",
    "        rsi_300s = getRelativeStrengthIndex(data_300s)\n",
    "        rsi_600s = getRelativeStrengthIndex(data_600s)\n",
    "        rsi_1800s = getRelativeStrengthIndex(data_1800s)\n",
    "        return [rv_300s, rv_600s, rv_1800s, rsi_300s, rsi_600s, rsi_1800s]\n",
    "\n",
    "    def _get_order_strength_index(self,t):\n",
    "        data_10s = self.msg[(self.msg.index<=self.episode_state.index[t])&(self.msg.index>=self.episode_state.index[t]-timedelta(seconds=10))]\n",
    "        data_60s = self.msg[(self.msg.index<=self.episode_state.index[t])&(self.msg.index>=self.episode_state.index[t]-timedelta(seconds=60))]\n",
    "        data_300s = self.msg[(self.msg.index<=self.episode_state.index[t])&(self.msg.index>=self.episode_state.index[t]-timedelta(seconds=300))]\n",
    "\n",
    "        svi_10s, sni_10s, lvi_10s, lni_10s, wvi_10s, wni_10s = getOrderStrengthIndex(data_10s)\n",
    "        svi_60s, sni_60s, lvi_60s, lni_60s, wvi_60s, wni_60s = getOrderStrengthIndex(data_60s)\n",
    "        svi_300s, sni_300s, lvi_300s, lni_300s, wvi_300s, wni_300s = getOrderStrengthIndex(data_300s)\n",
    "\n",
    "        return [\n",
    "            svi_10s, sni_10s, lvi_10s, lni_10s, wvi_10s, wni_10s,\n",
    "            svi_60s, sni_60s, lvi_60s, lni_60s, wvi_60s, wni_60s,\n",
    "            svi_300s, sni_300s, lvi_300s, lni_300s, wvi_300s, wni_300s\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90Kcyv494AY4"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dmblnyZf3S_S"
   },
   "outputs": [],
   "source": [
    "#env_continuous\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "class EnvContinuous(EnvFeature):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            code='000001',\n",
    "            day='20191101',\n",
    "            latency=1,\n",
    "            T=50,\n",
    "            # ablation states\n",
    "            wo_lob_state=False,\n",
    "            wo_market_state=False,\n",
    "            wo_agent_state=False,\n",
    "            # ablation rewards\n",
    "            wo_dampened_pnl=False,\n",
    "            wo_matched_pnl=False,\n",
    "            wo_inv_punish=False,\n",
    "            **kwargs\n",
    "        ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = \"Continuous\"\n",
    "        print(\"Environment:\", self.name)\n",
    "        self.code = code\n",
    "        self.day = day2date(day)\n",
    "\n",
    "        self.latency = latency\n",
    "        self.T = T\n",
    "\n",
    "        # ablation\n",
    "        self.wo_lob_state = wo_lob_state\n",
    "        self.wo_market_state = wo_market_state\n",
    "        self.wo_agent_state = wo_agent_state\n",
    "        self.r_da = 0 if wo_dampened_pnl else 1\n",
    "        self.r_ma = 0 if wo_matched_pnl else 1\n",
    "        self.r_ip = 0 if wo_inv_punish else 1\n",
    "\n",
    "        # Inventory punishment factor\n",
    "        self.theta = 0.01\n",
    "        self.eta = 0.9\n",
    "\n",
    "        self.init_states()\n",
    "\n",
    "        self.load_orderbook(code=code, day=day)\n",
    "        self.load_price(code=code, day=day)\n",
    "        self.load_trade(code=code, day=day)\n",
    "        self.load_msg(code=code, day=day)\n",
    "\n",
    "    def init_states(self):\n",
    "        self.__states_space__ = dict()\n",
    "        if not self.wo_lob_state:\n",
    "            self.__states_space__['lob_state'] = dict(\n",
    "                type='float',\n",
    "                shape=(self.T,40,1)\n",
    "                )\n",
    "        if not self.wo_market_state:\n",
    "            self.__states_space__['market_state'] = dict(\n",
    "                type='float',\n",
    "                shape=(24,)\n",
    "                )\n",
    "        if not self.wo_agent_state:\n",
    "            self.__states_space__['agent_state'] = dict(\n",
    "                type='float',\n",
    "                shape=(24,)\n",
    "                )\n",
    "\n",
    "    def states(self):\n",
    "        return self.__states_space__\n",
    "\n",
    "    def actions(self):\n",
    "        return dict(\n",
    "                    type='float',\n",
    "                    shape=(2,),\n",
    "                    min_value=-1,\n",
    "                    max_value=1\n",
    "                )\n",
    "\n",
    "    def max_episode_timesteps(self):\n",
    "        return self.__max_episode_timesteps__\n",
    "\n",
    "    def action2order(self, actions):\n",
    "        # t-latency\n",
    "        t_1_mid_price, t_1_a1_price, t_1_b1_price, t_1_spread = self.get_price_info(self.i-self.latency)\n",
    "\n",
    "        # action 1\n",
    "        # actions in [0, 1]\n",
    "        delta_price = actions[0]*0.05\n",
    "        spread = actions[1]*0.1\n",
    "        if self.inventory > 0:\n",
    "            reservation = t_1_mid_price - delta_price\n",
    "        elif self.inventory < 0:\n",
    "            reservation = t_1_mid_price + delta_price\n",
    "        else:\n",
    "            reservation = t_1_mid_price\n",
    "        ask_price = reservation + spread/2\n",
    "        bid_price = reservation - spread/2\n",
    "\n",
    "        # action 2\n",
    "        # actions in [-1, 1]\n",
    "        # delta_price = actions[0]*0.05\n",
    "        # spread = abs(actions[1])*0.1\n",
    "        # reservation = t_1_mid_price - delta_price\n",
    "        # ask_price = reservation + spread/2\n",
    "        # bid_price = reservation - spread/2\n",
    "\n",
    "        # action 3\n",
    "        # actions in [0, 1]\n",
    "        # ask_price = t_1_a1_price + actions[0]*0.1\n",
    "        # bid_price = t_1_b1_price - actions[1]*0.1\n",
    "        # reservation = (ask_price + bid_price)/2\n",
    "        # spread = ask_price - bid_price\n",
    "\n",
    "        ask_price, bid_price = price_legal_check(ask_price, bid_price)\n",
    "\n",
    "        # save for log\n",
    "        self.reservation = reservation\n",
    "        self.spread = spread\n",
    "\n",
    "        orders = {\n",
    "            'ask_price': ask_price,\n",
    "            'ask_vol': -TRADE_UNIT,\n",
    "            'bid_price': bid_price,\n",
    "            'bid_vol': TRADE_UNIT\n",
    "        }\n",
    "        return orders\n",
    "\n",
    "    def get_reward(self, trade_price, trade_volume):\n",
    "        pnl = self.value - self.value_\n",
    "\n",
    "        # Asymmetrically dampened PnL\n",
    "        asymmetric_dampen = max(0, self.eta * pnl)\n",
    "        dampened_pnl = pnl - asymmetric_dampen\n",
    "\n",
    "        matched_pnl = (self.mid_price - trade_price) * trade_volume\n",
    "\n",
    "        # delta_inventory = abs(self.inventory) - abs(self.inventory_)\n",
    "        # delta_inventory = max(0, delta_inventory)\n",
    "        # inventory_punishment = self.theta * (delta_inventory/TRADE_UNIT)\n",
    "\n",
    "        inventory_punishment = self.theta * (self.inventory/TRADE_UNIT)**2\n",
    "\n",
    "        # spread punishment\n",
    "        if self.inventory:\n",
    "            spread_punishment = 0\n",
    "        else:\n",
    "            spread_punishment = 100*self.spread if self.spread > 0.02 else 0\n",
    "\n",
    "        reward = pnl - spread_punishment#self.r_ma * matched_pnl + self.r_da * dampened_pnl - self.r_ip * inventory_punishment - spread_punishment\n",
    "\n",
    "        self.value_ = self.value\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def get_state_at_t(self, t):\n",
    "        self.__state__ = dict()\n",
    "\n",
    "        if not self.wo_lob_state:\n",
    "            lob = self.episode_state.iloc[t-self.T:t]\n",
    "            mid_price = (lob.ask1_price + lob.bid1_price)/2\n",
    "            lob_normed = lob_norm(lob, mid_price)\n",
    "            self.__state__['lob_state'] = np.expand_dims(np.array(lob_normed), -1)\n",
    "\n",
    "        if not self.wo_market_state:\n",
    "            self.__state__['market_state'] = self._get_market_state(t) + self._get_order_strength_index(t)\n",
    "\n",
    "        if not self.wo_agent_state:\n",
    "            self.__state__['agent_state'] = [self.inventory/(10*TRADE_UNIT)]*12 + [t / self.episode_length]*12\n",
    "\n",
    "        return self.__state__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZTBvC4jj3Wrj"
   },
   "outputs": [],
   "source": [
    "#env_discret\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EnvDiscrete(EnvFeature):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            code='000001',\n",
    "            day='20191101',\n",
    "            data_norm=True,\n",
    "            latency=1,\n",
    "            T=50,\n",
    "            # ablation states\n",
    "            wo_lob_state=False,\n",
    "            wo_market_state=False,\n",
    "            wo_agent_state=False,\n",
    "            # ablation rewards\n",
    "            wo_dampened_pnl=False,\n",
    "            wo_matched_pnl=False,\n",
    "            wo_inv_punish=False,\n",
    "            **kwargs\n",
    "        ):\n",
    "        super().__init__(**kwargs)\n",
    "        print(\"Environment: EnvDiscrete\")\n",
    "        self.code = code\n",
    "        self.day = day2date(day)\n",
    "\n",
    "        self.latency = latency\n",
    "        self.T = T\n",
    "\n",
    "        # ablation\n",
    "        self.wo_lob_state = wo_lob_state\n",
    "        self.wo_market_state = wo_market_state\n",
    "        self.wo_agent_state = wo_agent_state\n",
    "        self.r_da = 0 if wo_dampened_pnl else 1\n",
    "        self.r_ma = 0 if wo_matched_pnl else 1\n",
    "        self.r_ip = 0 if wo_inv_punish else 1\n",
    "\n",
    "        # Inventory punishment factor\n",
    "        self.theta = 0.01\n",
    "        self.eta = 0.5\n",
    "\n",
    "        self.init_states()\n",
    "\n",
    "        self.load_orderbook(code=code, day=day)\n",
    "        self.load_price(code=code, day=day)\n",
    "        self.load_trade(code=code, day=day)\n",
    "        self.load_msg(code=code, day=day)\n",
    "\n",
    "    def init_states(self):\n",
    "        self.__states_space__ = dict()\n",
    "        if not self.wo_lob_state:\n",
    "            self.__states_space__['lob_state'] = dict(\n",
    "                type='float',\n",
    "                shape=(self.T,40,1)\n",
    "                )\n",
    "        if not self.wo_market_state:\n",
    "            self.__states_space__['market_state'] = dict(\n",
    "                type='float',\n",
    "                shape=(24,)\n",
    "                )\n",
    "        if not self.wo_agent_state:\n",
    "            self.__states_space__['agent_state'] = dict(\n",
    "                type='float',\n",
    "                shape=(24,)\n",
    "                )\n",
    "\n",
    "    def states(self):\n",
    "        return self.__states_space__\n",
    "\n",
    "    def actions(self):\n",
    "        return dict(\n",
    "                    type='int',\n",
    "                    num_values=5\n",
    "                )\n",
    "\n",
    "    def max_episode_timesteps(self):\n",
    "        return self.__max_episode_timesteps__\n",
    "\n",
    "    def action2order(self, actions):\n",
    "        # t-latency\n",
    "        t_1_mid_price, t_1_a1_price, t_1_b1_price, t_1_spread = self.get_price_info(self.i-self.latency)\n",
    "\n",
    "        ask_price, bid_price = 0, 0\n",
    "        ask_volume, bid_volume = -TRADE_UNIT,TRADE_UNIT\n",
    "\n",
    "        if actions in range(7):\n",
    "            # limit order\n",
    "            if actions == 0:\n",
    "                ask_price = t_1_a1_price\n",
    "                bid_price = t_1_b1_price\n",
    "            elif actions == 1:\n",
    "                ask_price = t_1_a1_price\n",
    "                bid_price = t_1_b1_price-0.01\n",
    "            elif actions == 2:\n",
    "                ask_price = t_1_a1_price+0.01\n",
    "                bid_price = t_1_b1_price\n",
    "            elif actions == 3:\n",
    "                ask_price = t_1_a1_price+0.01\n",
    "                bid_price = t_1_b1_price-0.01\n",
    "            elif actions == 4:\n",
    "                ask_price = t_1_a1_price\n",
    "                bid_price = t_1_b1_price-0.02\n",
    "            elif actions == 5:\n",
    "                ask_price = t_1_a1_price+0.02\n",
    "                bid_price = t_1_b1_price\n",
    "            elif actions == 6:\n",
    "                ask_price = t_1_a1_price+0.02\n",
    "                bid_price = t_1_b1_price-0.02\n",
    "\n",
    "        elif actions==7:\n",
    "            # market order to clode position\n",
    "            if self.inventory < 0:\n",
    "                bid_price, bid_volume = np.inf, -self.inventory\n",
    "            elif self.inventory > 0:\n",
    "                ask_price, ask_volume = 0.01, -self.inventory\n",
    "            else:\n",
    "                trade_price, trade_volume = 0, 0\n",
    "\n",
    "        # inventory limit\n",
    "        if self.inventory < -10*TRADE_UNIT:\n",
    "            ask_price=0\n",
    "            ask_volume=0\n",
    "        elif self.inventory > 10*TRADE_UNIT:\n",
    "            bid_price=0\n",
    "            bid_volume=0\n",
    "\n",
    "        orders = {\n",
    "            'ask_price': ask_price,\n",
    "            'ask_vol': ask_volume,\n",
    "            'bid_price': bid_price,\n",
    "            'bid_vol': bid_volume\n",
    "        }\n",
    "\n",
    "        return orders\n",
    "\n",
    "    def get_reward(self, trade_price, trade_volume):\n",
    "        pnl = self.value - self.value_\n",
    "\n",
    "        # Asymmetrically dampened PnL\n",
    "        asymmetric_dampen = max(0, self.eta * pnl)\n",
    "        dampened_pnl = pnl - asymmetric_dampen\n",
    "\n",
    "        matched_pnl = (self.mid_price - trade_price) * trade_volume\n",
    "\n",
    "        delta_inventory = abs(self.inventory) - abs(self.inventory_)\n",
    "        # delta_inventory = max(0, delta_inventory)\n",
    "\n",
    "        inventory_punishment = self.theta * (delta_inventory/TRADE_UNIT)\n",
    "        # inventory_punishment = self.theta * (self.inventory/TRADE_UNIT)**2\n",
    "        reward = pnl\n",
    "        # reward = self.r_ma * matched_pnl + self.r_da * dampened_pnl - self.r_ip * inventory_punishment\n",
    "        self.value_ = self.value\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def get_state_at_t(self, t):\n",
    "        self.__state__ = dict()\n",
    "\n",
    "        if not self.wo_lob_state:\n",
    "            lob = self.episode_state.iloc[t-self.T:t]\n",
    "            mid_price = (lob.ask1_price + lob.bid1_price)/2\n",
    "            lob_normed = lob_norm(lob, mid_price)\n",
    "            self.__state__['lob_state'] = np.expand_dims(np.array(lob_normed), -1)\n",
    "\n",
    "        if not self.wo_market_state:\n",
    "            self.__state__['market_state'] = self._get_market_state(t) + self._get_order_strength_index(t)\n",
    "\n",
    "        if not self.wo_agent_state:\n",
    "            self.__state__['agent_state'] = [self.inventory/(10*TRADE_UNIT)]*12 + [t / self.episode_length]*12\n",
    "\n",
    "        return self.__state__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "2Po5FSdW1uCb",
    "outputId": "8bda9382-f20b-49a6-a805-c44108278b27"
   },
   "outputs": [],
   "source": [
    "#agent\n",
    "from tensorforce.agents import Agent\n",
    "\n",
    "def get_dueling_dqn_agent(\n",
    "                        network,\n",
    "                        environment=None,\n",
    "                        states=None,\n",
    "                        actions=None,\n",
    "                        max_episode_timesteps=None,\n",
    "                        batch_size=32,\n",
    "                        learning_rate=1e-4,\n",
    "                        horizon=1,\n",
    "                        discount=0.99,\n",
    "                        memory=200000,\n",
    "                        device='gpu'\n",
    "                        ):\n",
    "    if environment != None:\n",
    "        agent = Agent.create(\n",
    "        agent='dueling_dqn',\n",
    "        environment=environment,\n",
    "        max_episode_timesteps=max_episode_timesteps,\n",
    "        network=network,\n",
    "        config=dict(device=device),\n",
    "        memory=memory,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        horizon=horizon,\n",
    "        discount=discount,\n",
    "        parallel_interactions=10,\n",
    "    )\n",
    "    else:\n",
    "        agent = Agent.create(\n",
    "            agent='dueling_dqn',\n",
    "            states=states,\n",
    "            actions=actions,\n",
    "            max_episode_timesteps=max_episode_timesteps,\n",
    "            network=network,\n",
    "            config=dict(device=device),\n",
    "            memory=memory,\n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            horizon=horizon,\n",
    "            discount=discount,\n",
    "            parallel_interactions=10,\n",
    "        )\n",
    "    return agent\n",
    "\n",
    "def get_ppo_agent(\n",
    "                network,\n",
    "                environment=None,\n",
    "                states=None,\n",
    "                actions=None,\n",
    "                max_episode_timesteps=None,\n",
    "                batch_size=32,\n",
    "                learning_rate=1e-3,\n",
    "                horizon=None,\n",
    "                discount=0.99,\n",
    "                device='gpu'\n",
    "                ):\n",
    "    if environment != None:\n",
    "        agent = Agent.create(\n",
    "            agent='ppo',\n",
    "            environment=environment,\n",
    "            max_episode_timesteps=max_episode_timesteps,\n",
    "            network=network,\n",
    "            config=dict(device=device),\n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            discount=discount,\n",
    "            parallel_interactions=10,\n",
    "        )\n",
    "    else:\n",
    "        agent = Agent.create(\n",
    "            agent='ppo',\n",
    "            environment=environment,\n",
    "            states=states,\n",
    "            actions=actions,\n",
    "            max_episode_timesteps=max_episode_timesteps,\n",
    "            network=network,\n",
    "            config=dict(device=device),\n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            discount=discount,\n",
    "            parallel_interactions=10,\n",
    "        )\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "esR6R0cR3kXP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50, 40, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 50, 20, 32)   96          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 50, 20, 32)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 50, 20, 32)   4128        ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 50, 20, 32)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 50, 20, 32)   4128        ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 50, 20, 32)   0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 50, 4, 32)    5152        ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 50, 4, 32)    0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 50, 4, 32)    4128        ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 50, 4, 32)    0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 50, 4, 32)    4128        ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 50, 4, 32)    0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 50, 1, 32)    4128        ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 50, 1, 32)    0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 50, 1, 32)    4128        ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 50, 1, 32)    0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 50, 1, 32)    4128        ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 50, 1, 32)    0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 50, 1, 64)    2112        ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 50, 1, 64)    2112        ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 50, 1, 64)    0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 50, 1, 64)    0           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 50, 1, 32)    0           ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 50, 1, 64)    12352       ['leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 50, 1, 64)    20544       ['leaky_re_lu_11[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 50, 1, 64)    2112        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 50, 1, 64)    0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 50, 1, 64)    0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 50, 1, 64)    0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 50, 1, 192)   0           ['leaky_re_lu_10[0][0]',         \n",
      "                                                                  'leaky_re_lu_12[0][0]',         \n",
      "                                                                  'leaky_re_lu_13[0][0]']         \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 50, 192)      0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " tf_op_layer_strided_slice (Ten  [(None, 1, 192)]    0           ['reshape[0][0]']                \n",
      " sorFlowOpLayer)                                                                                  \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  ((None, 1, 64),     102944      ['tf_op_layer_strided_slice[0][0]\n",
      " dAttention)                     (None, 10, 1, 50))              ',                               \n",
      "                                                                  'reshape[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 64)           0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 176,320\n",
      "Trainable params: 176,320\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#network\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"-1\"\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True                                #\n",
    "K.set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "def get_lob_model(latent_dim, T):\n",
    "    lob_state = keras.layers.Input(shape=(T, 40, 1))\n",
    "\n",
    "    conv_first1 = keras.layers.Conv2D(32, (1, 2), strides=(1, 2))(lob_state)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\n",
    "    conv_first1 = keras.layers.Conv2D(32, (1, 5), strides=(1, 5))(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\n",
    "    conv_first1 = keras.layers.Conv2D(32, (1, 4))(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = keras.layers.Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\n",
    "    # build the inception module\n",
    "    convsecond_1 = keras.layers.Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n",
    "    convsecond_1 = keras.layers.Conv2D(64, (3, 1), padding='same')(convsecond_1)\n",
    "    convsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n",
    "\n",
    "    convsecond_2 = keras.layers.Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n",
    "    convsecond_2 = keras.layers.Conv2D(64, (5, 1), padding='same')(convsecond_2)\n",
    "    convsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n",
    "\n",
    "    convsecond_3 = keras.layers.MaxPooling2D((3, 1), strides=(1, 1), padding='same')(conv_first1)\n",
    "    convsecond_3 = keras.layers.Conv2D(64, (1, 1), padding='same')(convsecond_3)\n",
    "    convsecond_3 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_3)\n",
    "\n",
    "    convsecond_output = keras.layers.concatenate([convsecond_1, convsecond_2, convsecond_3], axis=3)\n",
    "    conv_reshape = keras.layers.Reshape((int(convsecond_output.shape[1]), int(convsecond_output.shape[3])))(convsecond_output)\n",
    "\n",
    "    attn_input = conv_reshape\n",
    "    attn_input_last = attn_input[:,-1:,:]\n",
    "\n",
    "    multi_head_attn_layer_1 = keras.layers.MultiHeadAttention(num_heads=10, key_dim=16, output_shape=64)\n",
    "\n",
    "    attn_output, weight = multi_head_attn_layer_1(attn_input_last, attn_input, return_attention_scores=True)\n",
    "\n",
    "    attn_output = keras.layers.Flatten()(attn_output)\n",
    "\n",
    "    # add Batch Normalization\n",
    "    # attn_output = keras.layers.BatchNormalization()(attn_output)\n",
    "\n",
    "    # add Layer Normalization\n",
    "    # attn_output = keras.layers.LayerNormalization()(attn_output)\n",
    "\n",
    "    return keras.models.Model(lob_state, attn_output)\n",
    "\n",
    "\n",
    "def get_fclob_model(latent_dim,T):\n",
    "    print(\"This is the FC-LOB model\")\n",
    "    lob_state = keras.layers.Input(shape=(T, 40, 1))\n",
    "\n",
    "    dense_input = keras.layers.Flatten()(lob_state)\n",
    "\n",
    "    dense_output = keras.layers.Dense(1024, activation='leaky_relu')(dense_input)\n",
    "    dense_output = keras.layers.Dense(256, activation='leaky_relu')(dense_input)\n",
    "    dense_output = keras.layers.Dense(latent_dim, activation='leaky_relu')(dense_input)\n",
    "\n",
    "    return keras.models.Model(lob_state, dense_output)\n",
    "\n",
    "def compute_output_shape(input_shape):\n",
    "    return (input_shape[0], 64)\n",
    "\n",
    "def get_pretrain_model(model, T):\n",
    "    lob_state = keras.layers.Input(shape=(T, 40, 1))\n",
    "    embedding = model(lob_state)\n",
    "    output = keras.layers.Dense(3, activation='softmax')(embedding)\n",
    "\n",
    "    return keras.models.Model(lob_state, output)\n",
    "\n",
    "def get_model(lob_model, T, with_lob_state=True, with_market_state=True, with_agent_state=True):\n",
    "    input_ls = list()\n",
    "    dense_input = list()\n",
    "    if with_lob_state:\n",
    "        lob_state = keras.layers.Input(shape=(T, 40, 1))\n",
    "        encoder_outputs = lob_model(lob_state)\n",
    "        input_ls.append(lob_state)\n",
    "        dense_input.append(encoder_outputs)\n",
    "    else:\n",
    "        print('w/o lob state!')\n",
    "\n",
    "    if with_agent_state:\n",
    "        agent_state = keras.layers.Input(shape=(24,))\n",
    "        input_ls.append(agent_state)\n",
    "        dense_input.append(agent_state)\n",
    "    else:\n",
    "         print('w/o agent state!')\n",
    "\n",
    "    if with_market_state:\n",
    "        market_state = keras.layers.Input(shape=(24,))\n",
    "        input_ls.append(market_state)\n",
    "        dense_input.append(agent_state)\n",
    "    else:\n",
    "        print('w/o market state!')\n",
    "\n",
    "    dense_input = keras.layers.concatenate(dense_input, axis=1)\n",
    "\n",
    "    dense_output = keras.layers.Dense(64, activation='leaky_relu')(dense_input)\n",
    "\n",
    "    return keras.models.Model(input_ls, dense_output)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_lob_model(64,50).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1bnkJG_F3qVI"
   },
   "outputs": [],
   "source": [
    "#main\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "import pyrallis\n",
    "from dataclasses import asdict, dataclass\n",
    "\n",
    "from tensorforce.environments import Environment\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    # Experiment\n",
    "    code: str = '000001'\n",
    "    device: str = \"cpu\"\n",
    "    latency: int = 1\n",
    "    time_window: int = 50\n",
    "    log: bool = False\n",
    "    exp_name: str = ''\n",
    "    # Agent\n",
    "    agent_type: str = 'ppo' # ppo/dueling dqn\n",
    "    learning_rate: int = 1e-4\n",
    "    horizon: int = 1\n",
    "    env_type: str = 'continuous' # continuous/discrete\n",
    "    load: bool = False\n",
    "    agent_load_dir: str = ''\n",
    "    save: bool = False,\n",
    "    agent_save_dir: str = ''\n",
    "    # Ablation\n",
    "    wo_pretrain: bool = False\n",
    "    wo_attnlob: bool = False\n",
    "    wo_lob_state: bool = False\n",
    "    wo_market_state: bool = False\n",
    "    wo_dampened_pnl: bool = False\n",
    "    wo_matched_pnl: bool = False\n",
    "    wo_inv_punish: bool = False\n",
    "\n",
    "\n",
    "def init_env(day, config):\n",
    "    if config['env_type'] == 'continuous':\n",
    "        env = EnvContinuous\n",
    "    elif config['env_type'] == 'discrete':\n",
    "        env = EnvDiscrete\n",
    "\n",
    "    environment = env(\n",
    "        code=config['code'],\n",
    "        day=day,\n",
    "        latency=config['latency'],\n",
    "        T=config['time_window'],\n",
    "        # state ablation\n",
    "        wo_lob_state=config['wo_lob_state'],\n",
    "        wo_market_state=config['wo_market_state'],\n",
    "        # reward ablation\n",
    "        wo_dampened_pnl=config['wo_dampened_pnl'],\n",
    "        wo_matched_pnl=config['wo_matched_pnl'],\n",
    "        wo_inv_punish=config['wo_inv_punish'],\n",
    "        # exp setting\n",
    "        experiment_name=config['exp_name'],\n",
    "        log=config['log'],\n",
    "        )\n",
    "    return environment\n",
    "\n",
    "def init_agent(environment, config):\n",
    "    kwargs=dict()\n",
    "    if config['agent_type'] == 'dueling_dqn':\n",
    "        get_agent = get_dueling_dqn_agent\n",
    "        kwargs['learning_rate']=config['learning_rate']\n",
    "        kwargs['horizon']=config['horizon']\n",
    "    elif config['agent_type'] == 'ppo':\n",
    "        get_agent = get_ppo_agent\n",
    "        kwargs['learning_rate']=config['learning_rate']\n",
    "        kwargs['horizon']=config['horizon']\n",
    "\n",
    "    if config['wo_pretrain']:\n",
    "        print(\"Ablation: pretrain\")\n",
    "        lob_model = get_lob_model(64,config['time_window'])\n",
    "        lob_model.compute_output_shape = compute_output_shape\n",
    "    else:\n",
    "        pretrain_model_dir = f'./ckpt/pretrain_model_' + config['code']\n",
    "        model = get_lob_model(64,config['time_window'])\n",
    "        model.compute_output_shape = compute_output_shape\n",
    "        model_pretrain = get_pretrain_model(model,config['time_window'])\n",
    "        checkpoint_filepath = pretrain_model_dir + '/weights'\n",
    "        model_pretrain.load_weights(checkpoint_filepath)\n",
    "        lob_model = model_pretrain.layers[1]\n",
    "\n",
    "    if config['wo_attnlob']:\n",
    "        print(\"Ablation: attnlob\")\n",
    "        lob_model = get_fclob_model(64,config['time_window'])\n",
    "\n",
    "    model = get_model(\n",
    "        lob_model,\n",
    "        config['time_window'],\n",
    "        with_lob_state= not config['wo_lob_state'],\n",
    "        with_market_state= not config['wo_market_state']\n",
    "        )\n",
    "    agent = get_agent(model, environment=environment, max_episode_timesteps=1000, device=config['device'], **kwargs)\n",
    "\n",
    "    if config['load']:\n",
    "        model = keras.models.load_model(keras_model_dir)\n",
    "        model.layers[1].compute_output_shape = compute_output_shape\n",
    "        agent = get_agent(model, environment=environment, max_episode_timesteps=1000, device=config['device'], **kwargs)\n",
    "        agent.restore(config['agent_load_dir'], filename='cppo', format='numpy')\n",
    "\n",
    "    return agent\n",
    "\n",
    "def train_a_day(environment, agent, train_result):\n",
    "    num_episodes = len(environment.orderbook)//num_step_per_episode\n",
    "    data_collector = list()\n",
    "    for idx in tqdm(range(num_episodes)):\n",
    "        episode_states = list()\n",
    "        episode_actions = list()\n",
    "        episode_terminal = list()\n",
    "        episode_reward = list()\n",
    "\n",
    "        states = environment.reset_seq(timesteps_per_episode=num_step_per_episode, episode_idx=idx)\n",
    "        terminal = False\n",
    "        while not terminal:\n",
    "            episode_states.append(states)\n",
    "            actions = agent.act(states=states, independent=True)\n",
    "            episode_actions.append(actions)\n",
    "            states, terminal, reward = environment.execute(actions=actions)\n",
    "            episode_terminal.append(terminal)\n",
    "            episode_reward.append(reward)\n",
    "\n",
    "        data_collector.append([episode_states, episode_actions, episode_terminal, episode_reward])\n",
    "\n",
    "        agent.experience(\n",
    "            states=episode_states,\n",
    "            actions=episode_actions,\n",
    "            terminal=episode_terminal,\n",
    "            reward=episode_reward\n",
    "        )\n",
    "\n",
    "        agent.update()\n",
    "\n",
    "        save_episode_result(environment, train_result)\n",
    "\n",
    "    return episode_states, episode_actions, episode_reward\n",
    "\n",
    "def test_a_day(environment, agent, test_result):\n",
    "    num_episodes = len(environment.orderbook)//num_step_per_episode\n",
    "    for idx in tqdm(range(num_episodes)):\n",
    "\n",
    "        states = environment.reset_seq(timesteps_per_episode=num_step_per_episode, episode_idx=idx)\n",
    "        terminal = False\n",
    "        while not terminal:\n",
    "            actions = agent.act(\n",
    "                states=states, independent=True\n",
    "            )\n",
    "            states, terminal, reward = environment.execute(actions=actions)\n",
    "\n",
    "        save_episode_result(environment, test_result)\n",
    "\n",
    "def train(agent, train_result, config):\n",
    "    for day in train_days:\n",
    "        environment = init_env(day, config)\n",
    "        train_a_day(environment, agent, train_result)\n",
    "\n",
    "def test(agent, test_result, config):\n",
    "    for day in test_days:\n",
    "        environment = init_env(day, config)\n",
    "        test_a_day(environment, agent, test_result)\n",
    "\n",
    "def save_episode_result(environment, test_result):\n",
    "    res_dict = environment.get_final_result()\n",
    "    date = environment.day\n",
    "    idx = environment.episode_idx\n",
    "\n",
    "    test_result.loc[date+'_'+str(idx)] = [res_dict['pnl'], res_dict['nd_pnl'], res_dict['avg_abs_position'], res_dict['profit_ratio'], res_dict['volume']]\n",
    "\n",
    "def gather_test_results(test_result):\n",
    "    day_list = list(test_result.index)\n",
    "    for i in range(len(day_list)):\n",
    "        day_list[i] = day_list[i][:10]\n",
    "    day_list = set(day_list)\n",
    "    gathered_results = pd.DataFrame(columns=['PnL', 'ND-PnL', 'average_position', 'profit_ratio', 'volume'])\n",
    "    for day in day_list:\n",
    "        result = test_result[test_result.index.str.contains(day)]\n",
    "        pnl = result.PnL.sum()\n",
    "        nd_pnl = result['ND-PnL'].sum()\n",
    "        ap = result.average_position.mean()\n",
    "        volume = (result.PnL/result.profit_ratio).sum()\n",
    "        pr = pnl/volume\n",
    "        gathered_results.loc[day] = [pnl,nd_pnl,ap,pr,volume]\n",
    "    gathered_results=gathered_results.sort_index()\n",
    "    return gathered_results\n",
    "\n",
    "def save_agent(agent, config):\n",
    "    # save agent network\n",
    "    agent.model.policy.network.keras_model.save(keras_model_dir)\n",
    "    # Save agent\n",
    "    agent.save(config['agent_save_dir'], filename=agent, format='numpy')\n",
    "\n",
    "#@pyrallis.wrap()\n",
    "def main(config: TrainConfig):\n",
    "    config = asdict(config)\n",
    "\n",
    "    environment = init_env(train_days[0], config)\n",
    "    agent = init_agent(environment, config)\n",
    "\n",
    "    train_result = pd.DataFrame(columns=['PnL', 'ND-PnL', 'average_position', 'profit_ratio', 'volume'])\n",
    "    for _ in range(n_train_loop):\n",
    "        train(agent, train_result, config)\n",
    "        if config['save']:\n",
    "            save_agent(agent, config)\n",
    "\n",
    "    test_result = pd.DataFrame(columns=['PnL', 'ND-PnL', 'average_position', 'profit_ratio', 'volume'])\n",
    "    test(agent, test_result, config)\n",
    "    daily_test_results = gather_test_results(test_result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: Continuous\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/000001/20191101/ask.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m n_train_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      7\u001b[0m config \u001b[38;5;241m=\u001b[39m TrainConfig()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 204\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(config: TrainConfig):\n\u001b[1;32m    202\u001b[0m     config \u001b[38;5;241m=\u001b[39m asdict(config)\n\u001b[0;32m--> 204\u001b[0m     environment \u001b[38;5;241m=\u001b[39m \u001b[43minit_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_days\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     agent \u001b[38;5;241m=\u001b[39m init_agent(environment, config)\n\u001b[1;32m    207\u001b[0m     train_result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPnL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mND-PnL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage_position\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofit_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[26], line 50\u001b[0m, in \u001b[0;36minit_env\u001b[0;34m(day, config)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menv_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscrete\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     48\u001b[0m     env \u001b[38;5;241m=\u001b[39m EnvDiscrete\n\u001b[0;32m---> 50\u001b[0m environment \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mday\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mday\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime_window\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# state ablation\u001b[39;49;00m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwo_lob_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwo_lob_state\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwo_market_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwo_market_state\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# reward ablation\u001b[39;49;00m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwo_dampened_pnl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwo_dampened_pnl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwo_matched_pnl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwo_matched_pnl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwo_inv_punish\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwo_inv_punish\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# exp setting\u001b[39;49;00m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexp_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m environment\n",
      "Cell \u001b[0;32mIn[15], line 51\u001b[0m, in \u001b[0;36mEnvContinuous.__init__\u001b[0;34m(self, code, day, latency, T, wo_lob_state, wo_market_state, wo_agent_state, wo_dampened_pnl, wo_matched_pnl, wo_inv_punish, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_states()\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_orderbook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mday\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mday\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_price(code\u001b[38;5;241m=\u001b[39mcode, day\u001b[38;5;241m=\u001b[39mday)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_trade(code\u001b[38;5;241m=\u001b[39mcode, day\u001b[38;5;241m=\u001b[39mday)\n",
      "Cell \u001b[0;32mIn[12], line 61\u001b[0m, in \u001b[0;36mBaseEnv.load_orderbook\u001b[0;34m(self, code, day)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_orderbook\u001b[39m(\u001b[38;5;28mself\u001b[39m, code, day):\n\u001b[0;32m---> 61\u001b[0m     ask \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mday\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/ask.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     bid \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mday\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/bid.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morderbook \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([ask, bid], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/000001/20191101/ask.csv'"
     ]
    }
   ],
   "source": [
    "train_days=['20191101', '20191104', '20191105', '20191106', '20191107', '20191108', '20191111', '20191112']\n",
    "test_days=['20191113', '20191114', '20191115', '20191118', '20191119', '20191120',\n",
    "            '20191121', '20191122', '20191125', '20191126', '20191127', '20191128', '20191129']\n",
    "num_step_per_episode = 2000\n",
    "n_train_loop = 5\n",
    "\n",
    "config = TrainConfig()\n",
    "main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNHEqJfGg3wJQ/uhmBDeDkI",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
